{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Studying the trade-off between exploration and exploitation\n",
    "# The agent tries to learn the optimal policy in a maze\n",
    "# The maze has two-way portals in it... See maze.py for attributions.\n",
    "\n",
    "%matplotlib inline\n",
    "import gym\n",
    "import gym_maze\n",
    "from maze import simulate, average_win_episode, new_maze, plot_episodes_against_parameter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can teach the agent to navigate the maze using different methods for exploration,\n",
    "# Epsilon Greedy (EG), Decaying-EG (ED) or Upper Confidence Bounds (UCB)\n",
    "\n",
    "# The usage for each parameter is documented in maze.py\n",
    "params = {\n",
    "    \"winning_streak\": 80,\n",
    "    \"policy\": \"EG\",\n",
    "    \"epsilon\": 0.2,\n",
    "    \"learning_rate\": 1.0,\n",
    "    \"starting_value\": 0.0,\n",
    "    \"display\": False\n",
    "}\n",
    "\n",
    "winning_episode = simulate(maze=new_maze(), n_episodes=1000, **params)[\"winning_episode\"] \n",
    "print(f\"The maze was learnt in {winning_episode} episodes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase these values for better plots!\n",
    "n_mazes = 100\n",
    "n_levels = 10\n",
    "\n",
    "# *--- EPSILON-GREEDY (EG) ---*\n",
    "# Best initialization value for Epsilon-Greedy\n",
    "initial_values = np.linspace(-1.0, 2.0, int(n_levels/3.0))\n",
    "plot_y = plot_episodes_against_parameter(\"starting_value\", initial_values, \n",
    "                                               params, n_mazes=n_mazes)\n",
    "\n",
    "# Check whether it's beneficial to use optimistic initialization. \n",
    "# Does that change if epsilon (exploration) is 0.0?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's choose the best 'starting_value'\n",
    "params[\"starting_value\"] = initial_values[np.argmin(plot_y)]\n",
    "\n",
    "# Best Epsilon for Epsilon-Greedy (with best initialization value)\n",
    "params[\"learning_rate\"] = 1.0\n",
    "epsilons = np.linspace(0.0, 0.5, n_levels)\n",
    "plot_y = plot_episodes_against_parameter(\"epsilon\", epsilons, \n",
    "                                               params, n_mazes=n_mazes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's choose the best 'epsilon'\n",
    "params[\"epsilon\"] = epsilons[np.argmin(plot_y)]\n",
    "\n",
    "# Best Learning-Rate for Epsilon-Greedy\n",
    "learning_rates = np.linspace(0.001, 1.5, n_levels)\n",
    "plot_y = plot_episodes_against_parameter(\"learning_rate\", learning_rates, \n",
    "                                               params, n_mazes=n_mazes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *--- DECAYING EPSILON-GREEDY (ED) ---*\n",
    "params[\"policy\"] = \"ED\"\n",
    "params[\"epsilon\"] = 0.3\n",
    "params[\"learning_rate\"] = 1.15\n",
    "params[\"starting_value\"] = 0.3\n",
    "\n",
    "n_mazes_small = int(n_mazes/5)\n",
    "# Best decay-factor and learning rate (3-step optimization)\n",
    "# First optimize decay-factor\n",
    "decay_factors = np.linspace(0.0, 1.0, n_levels)\n",
    "plot_y = plot_episodes_against_parameter(\"decay\", decay_factors, params, n_mazes=n_mazes_small, view_plot=False)\n",
    "params[\"decay\"] = decay_factors[np.argmin(plot_y)]\n",
    "\n",
    "# Then the learning rate\n",
    "learning_rates = np.linspace(0.1, 1.5, n_levels)\n",
    "plot_y = plot_episodes_against_parameter(\"learning_rate\", learning_rates, params, n_mazes=n_mazes_small, view_plot=False)\n",
    "params[\"learning_rate\"] = learning_rates[np.argmin(plot_y)]\n",
    "\n",
    "# Then the epsilon\n",
    "epsilons = np.linspace(0.1, 1.1, n_levels)\n",
    "plot_y = plot_episodes_against_parameter(\"learning_rate\", learning_rates, params, n_mazes=n_mazes_small, view_plot=False)\n",
    "params[\"learning_rate\"] = learning_rates[np.argmin(plot_y)]\n",
    "\n",
    "# Then the decay factor\n",
    "decay_factors = np.linspace(0.0, 1.0, n_levels)\n",
    "plot_y = plot_episodes_against_parameter(\"decay\", decay_factors, params, n_mazes=n_mazes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *--- UPPER CONFIDENCE BOUNDS (UCB) ---*\n",
    "params[\"policy\"] = \"UCB\"\n",
    "params[\"epsilon\"] = 0.1\n",
    "params[\"learning_rate\"] = 0.5\n",
    "params[\"starting_value\"] = 0.0\n",
    "\n",
    "# Best decay-factor (UCB values decay everytime a state-action is visited)\n",
    "decay_factors = np.linspace(0.1, 1.0, n_levels)\n",
    "plot_y = plot_episodes_against_parameter(\"decay\", decay_factors, \n",
    "                                               params, n_mazes=n_mazes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Gym",
   "language": "python",
   "name": "gym"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
